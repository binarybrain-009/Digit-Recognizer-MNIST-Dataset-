{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b8f23803-f7c9-c890-22dd-eab6672e749c"
   },
   "source": [
    "## Convolutional Neural Networks\n",
    "References\n",
    "\n",
    "  [1]: http://yann.lecun.com/exdb/lenet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "19d8eb6b-9b71-029c-06e1-7e74975ae669"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8e18fecf-bc7e-dd8d-0894-2601c3f69e97"
   },
   "source": [
    "If you don't already have [Keras][1], you can easily install it through conda or pip. It relies on either tensorflow or theano, so you should have these installed first. Keras is already available here in the kernel and on Amazon deep learning AMI.\n",
    "\n",
    "  [1]: https://keras.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "76adcf6f-d109-e47d-d8f0-c7a26e986df5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5c6e32c743a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m \u001b[1;31m# convert to one-hot-encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxPool2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "249daad0-7a0d-ad43-2bf9-4861ffac0d90"
   },
   "outputs": [],
   "source": [
    "train_file = \"../input/train.csv\"\n",
    "test_file = \"../input/test.csv\"\n",
    "output_file = \"submission.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b3a8472f-d3a1-949d-3bb4-2935b53c4f17"
   },
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fc8110b9-1087-2221-1399-6d218a494319"
   },
   "source": [
    "we split the data into a training set and a validation set, so that we can evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "95cd483d-23ae-fa98-3823-724e41ed4b5b"
   },
   "outputs": [],
   "source": [
    "raw_data = np.loadtxt(train_file, skiprows=1, dtype='int', delimiter=',')\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    raw_data[:,1:], raw_data[:,0], test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ffbcd0ae-c1a0-b52c-ea4e-5c691e893333"
   },
   "source": [
    "Each data point consists of 784 values. A fully connected net just treats all these values the same, but a CNN treats it as a 28x28 square. Thes two graphs explain the difference: It's easy to understand why a CNN can get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "77036419-61ff-a6a5-6b67-fa39f1147d11"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(12,6))\n",
    "ax[0].plot(x_train[0])\n",
    "ax[0].set_title('784x1 data')\n",
    "ax[1].imshow(x_train[0].reshape(28,28), cmap='gray')\n",
    "ax[1].set_title('28x28 data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dcee4998-a863-3dd9-57f9-0bde1b2f5099"
   },
   "source": [
    "We now reshape all data this way. Keras wants an extra dimension in the end, for channels. If this had been RGB images, there would have been 3 channels, but as MNIST is gray scale it only uses one.\n",
    "\n",
    "\n",
    "\n",
    "  [1]: https://keras.io/backend/#set_image_dim_ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c32f7260-7973-31a4-3991-1bbac6c36b47"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_val = x_val.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c291c473-5e0e-a947-bea6-22d5feb81797"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\")/255.\n",
    "x_val = x_val.astype(\"float32\")/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7a60023f-8844-a721-0ff9-39dfd82e0dd5"
   },
   "source": [
    "Using one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fdc43c64-0655-e91d-0659-ceb97a6f3532"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "#example:\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "71f04810-96c8-bc4d-1938-381e2e4b4ec8"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "The convolutional layers Conv2D have 16-32 filters that use nine weights each to transform a pixel to a weighted average of itself and its eight neighbors. As the same nine weights are used over the whole image, the net will pick up features that are useful everywhere. As it is only nine weights, we can stack many convolutional layers on top of each other without running out of memory/time. \n",
    "\n",
    "The MaxPooling layers just look at four neighboring pixels and picks the maximal value. This reduces the size of the image by half, and by combining convolutional and pooling layers, the net be able to combine its features to learn more global features of the image. In the end we use the features in two fully-connected (Dense) layers.\n",
    "\n",
    "Batch Normalization is a technical trick to make training faster. Dropout is a regularization method, where the layer randomly replaces  a proportion of its weights to zero for each training sample. This forces the net to learn features in a distributed way, not relying to much on a particular weight, and therefore improves generalization. 'relu' is the activation function x -> max(x,0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "363e8bc8-a731-01da-9a39-d3914ea7a5c8"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu',\n",
    "                 input_shape = (28, 28, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bb0658c9-59f1-5336-9e5d-abcd82010238"
   },
   "source": [
    "Another important method to improve generalization is augmentation. This means generating more training data by randomly perturbing the images. If done in the right way, it can force the net to only learn translation-invariant features. If you train this model over hundreds of epochs, augmentation will definitely improve your performance. Here in the Kernel, we will only look at each image 4-5 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c34d0682-2777-382d-ab1c-fa0186fc0ae7"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(zoom_range = 0.1,\n",
    "                            height_shift_range = 0.1,\n",
    "                            width_shift_range = 0.1,\n",
    "                            rotation_range = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d0acbcf9-0be3-712f-222d-58e6670dac58"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer = Adam(lr=1e-4), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f8c4ffdf-abb0-7c28-b10b-16c5714b92d0"
   },
   "source": [
    "We train once with a smaller learning rate to ensure convergence. We then speed things up, only to reduce the learning rate by 10% every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "856a2d69-b0eb-6962-5323-fd2819d0be24"
   },
   "outputs": [],
   "source": [
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b8d960a3-09ed-0802-2b23-4ed583f7492b"
   },
   "outputs": [],
   "source": [
    "hist = model.fit_generator(datagen.flow(x_train, y_train, batch_size=16),\n",
    "                           steps_per_epoch=500,\n",
    "                           epochs=20, #Increase this when not on Kaggle kernel\n",
    "                           verbose=2,  #1 for ETA, 0 for silent\n",
    "                           validation_data=(x_val[:400,:], y_val[:400,:]), #For speed\n",
    "                           callbacks=[annealer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9ceb04e7-b196-b2ca-ce2b-abcdc8870bcc"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c64f7ec3-6af5-d3e6-e0e4-21f8e29d969c"
   },
   "source": [
    "We only used a subset of the validation set during training, to save time. Now the perfomance is checked on whole validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d3a2a555-ef78-1cce-3971-0ea4f7bb0c1d"
   },
   "outputs": [],
   "source": [
    "final_loss, final_acc = model.evaluate(x_val, y_val, verbose=0)\n",
    "print(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss, final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "49fd9696-826d-f95c-3fe6-94fe4d1f0a6c"
   },
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'], color='b')\n",
    "plt.plot(hist.history['val_loss'], color='r')\n",
    "plt.show()\n",
    "plt.plot(hist.history['acc'], color='b')\n",
    "plt.plot(hist.history['val_acc'], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0783efce-d6b9-6d98-3824-0b45260a0f23"
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_val)\n",
    "y_pred = np.argmax(y_hat, axis=1)\n",
    "y_true = np.argmax(y_val, axis=1)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5375f3d0-51fd-7199-4109-b32bcb4a4e63"
   },
   "source": [
    "\n",
    "There are a few parameters that could be tweaked (number of layers, number of filters, Dropout parameters, learning rate, augmentation settings)using trial and error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0bd63110-f8f6-6f39-3225-c2f941184f3b"
   },
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "002ce4ad-9a8f-8a1e-c658-40f9c371f91d"
   },
   "outputs": [],
   "source": [
    "mnist_testset = np.loadtxt(test_file, skiprows=1, dtype='int', delimiter=',')\n",
    "x_test = mnist_testset.astype(\"float32\")\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7413800d-21c3-654f-8b39-27e3df9c4391"
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "074aabf5-4a9a-bfdb-cbdd-0a8f06dc5fae"
   },
   "source": [
    "y_hat consists of class probabilities (corresponding to the one-hot encoding of the training labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "575d9348-99ec-9b8c-f5a5-ceac44c5308d"
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_hat,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cbf31eb1-2ffd-efb5-e2b2-b4dda99fa1da"
   },
   "outputs": [],
   "source": [
    "with open(output_file, 'w') as f :\n",
    "    f.write('ImageId,Label\\n')\n",
    "    for i in range(len(y_pred)) :\n",
    "        f.write(\"\".join([str(i+1),',',str(y_pred[i]),'\\n']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5591673a-99e2-2269-8cc9-55573d49e029"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
